akka.loglevel=INFO
akka.loggers=["akka.event.slf4j.Slf4jLogger"]
akka.logging-filter="akka.event.slf4j.Slf4jLoggingFilter"
akka.actor.provider="akka.remote.RemoteActorRefProvider"
akka.remote.enabled-transports=["akka.remote.netty.tcp"]
akka.remote.netty.tcp.hostname = 192.168.0.102
akka.remote.netty.tcp.port = 19091






# Possibility to turn off logging of dead letters while the actor system #
# is shutting down. Logging is only done when enabled by 'log-dead-letters' #
# setting. #
//akka.jvm-exit-on-fatal-error=on
//akka.log-dead-letters-during-shutdown=on
//akka.actor.warn-about-java-serializer-usage=off

//akka.actor.default-mailbox.mailbox-type="akka.dispatch.SingleConsumerOnlyUnboundedMailbox"
//akka.actor.serializers.kryo="com.twitter.chill.akka.AkkaSerializer"
//akka.actor.serializers.proto="akka.remote.serialization.ProtobufSerializer"
//akka.actor.serialization-bindings."scala.Enumeration"=kryo
//akka.actor.serialization-bindings."scala.Enumeration$Val"=kryo
//akka.actor.serialization-bindings."scala.Product"=kryo
//akka.actor.serialization-bindings."scala.collection.Traversable"=kryo
//akka.actor.serialization-bindings."java.io.Serializable"=kryo
//# How often failure detection heartbeat messages should be sent #
//akka.contrib.cluster.client.heartbeat-interval=10s
//# Number of potentially lost/delayed heartbeats that will be #
//# accepted before considering it to be an anomaly. #
//# The ClusterClient is using the akka.remote.DeadlineFailureDetector, which #
//# will trigger if there are no heartbeats within the duration #
//# heartbeat-interval + acceptable-heartbeat-pause, i.e. 15 seconds with #
//# the default settings. #
//akka.contrib.cluster.client.acceptable-heartbeat-pause=1s
//akka.contrib.cluster.client.establishing-get-contacts-interval=3s
//akka.contrib.cluster.client.refresh-contacts-interval=2s
//akka.contrib.cluster.client.buffer-size=10000
//akka.contrib.cluster.client.reconnect-timeout=5s
//akka.contrib.cluster.client.mailbox.mailbox-type="akka.dispatch.UnboundedDequeBasedMailbox"
//akka.contrib.cluster.client.mailbox.stash-capacity=1000

//akka.remote.watch-failure-detector.heartbeat-interval=1000s   #
//akka.remote.watch-failure-detector.max-sample-size=2000000000
//akka.remote.watch-failure-detector.acceptable-heartbeat-pause=6000s  # default 10s #
//akka.remote.watch-failure-detector.expected-response-after=1s
//akka.remote.transport-failure-detector.heartbeat-interval=1000s   # default 4s #
//akka.remote.transport-failure-detector.acceptable-heartbeat-pause=6000s  # default 10s #
//akka.remote.transport-failure-detector.expected-response-after=1s
//akka.remote.compression-scheme="zlib" # Options: "zlib" (lzf to come), leave out for no compression #
//akka.remote.zlib-compression-level=6  # Options: 0-9 (1 being fastest and 9 being the most compressed), default is 6 #
//akka.remote.maximum-payload-bytes=30000000 bytes
//
//
//# After catastrophic communication failures that result in the loss of system
//# messages or after the remote DeathWatch triggers the remote system gets
//# quarantined to prevent inconsistent behavior.
//# This setting controls how long the Quarantine marker will be kept around
//# before being removed to avoid long-term memory leaks.
//# WARNING: DO NOT change this to a small value to re-enable communication with
//# quarantined nodes. Such feature is not supported and any behavior between
//# the affected systems after lifting the quarantine is undefined.
//akka.remote.prune-quarantine-marker-after = 5 d
//
//# If system messages have been exchanged between two systems (i.e. remote death
//# watch or remote deployment has been used) a remote system will be marked as
//# quarantined after the two system has no active association, and no
//# communication happens during the time configured here.
//# The only purpose of this setting is to avoid storing system message redelivery
//# data (sequence number state, etc.) for an undefined amount of time leading to long
//# term memory leak. Instead, if a system has been gone for this period,
//# or more exactly
//# - there is no association between the two systems (TCP connection, if TCP transport is used)
//# - neither side has been attempting to communicate with the other
//# - there are no pending system messages to deliver
//# for the amount of time configured here, the remote system will be quarantined and all state
//# associated with it will be dropped.
//akka.remote.quarantine-after-silence = 6 d
//
//
//
//# After failed to establish an outbound connection, the remoting will mark the
//# address as failed. This configuration option controls how much time should
//# be elapsed before reattempting a new connection. While the address is
//# gated, all messages sent to the address are delivered to dead-letters.
//# If this setting is 0, the remoting will always immediately reattempt
//# to establish a failed outbound connection and will buffer writes until
//# it succeeds.
//akka.remote.retry-gate-closed-for = 1
//
//# If the retry gate function is disabled (see retry-gate-closed-for) the
//# remoting subsystem will always attempt to reestablish failed outbound
//# connections. The settings below together control the maximum number of
//# reattempts in a given time window. The number of reattempts during
//# a window of "retry-window" will be maximum "maximum-retries-in-window".
//akka.remote.retry-window=60 s
//akka.remote.maximum-retries-in-window=10
//# The length of time to gate an address whose name lookup has failed
//# or has explicitly signalled that it will not accept connections
//# (remote system is shutting down or the requesting system is quarantined).
//# No connection attempts will be made to an address while it remains
//# gated. Any messages sent to a gated address will be directed to dead
//# letters instead. Name lookups are costly, and the time to recovery
//# is typically large, therefore this setting should be a value in the
//# order of seconds or minutes.
//akka.remote.gate-invalid-addresses-for=6 d
//# This settings controls how long a system will be quarantined after
//# catastrophic communication failures that result in the loss of system
//# messages. Quarantining prevents communication with the remote system
//# of a given UID. This function can be disabled by setting the value
//# to "off".
//akka.remote.quarantine-systems-for=6 d
//# This setting defines the maximum number of unacknowledged system messages
//# allowed for a remote system. If this limit is reached the remote system is
//# declared to be dead and its UID marked as tainted.
//akka.remote.system-message-buffer-size=100000000
//# This setting defines the maximum idle time after an individual
//# acknowledgement for system messages is sent. System message delivery
//# is guaranteed by explicit acknowledgement messages. These acks are
//# piggybacked on ordinary traffic messages. If no traffic is detected
//# during the time period configured here, the remoting will send out
//# an individual ack.
//akka.remote.system-message-ack-piggyback-timeout=10 s
//# This setting defines the time after messages that have not been
//# explicitly acknowledged or negatively acknowledged are resent.
//# Messages that were negatively acknowledged are always immediately
//# resent.
//akka.remote.resend-interval=1 s
//# Sets the send buffer size of the Sockets, default is 0b #
//akka.remote.netty.tcp.send-buffer-size=30000000b
//# Sets the receive buffer size of the Sockets, default is 0b #
//akka.remote.netty.tcp.receive-buffer-size=30000000b
//# Maximum message size the transport will accept, but at least 32000 bytes. #
//# Please note that UDP does not support arbitrary large datagrams, #
//# so this setting has to be chosen carefully when using UDP. #
//# Both send-buffer-size and receive-buffer-size settings has to #
//# be adjusted to be able to buffer messages of maximum size. #
//akka.remote.netty.tcp.maximum-frame-size=30000000b
//akka.remote.netty.tcp.message-frame-size=30000000b
//# Enable SSL/TLS encryption. #
//# This must be enabled on both the client and server to work. #
//akka.remote.netty.ssl.enable-ssl=true
//# This is the Java Key Store used by the server connection #
//akka.remote.netty.ssl.security.key-store="kapp.keystore"
//# This password is used for decrypting the key store #
//akka.remote.netty.ssl.security.key-store-password="raysdata@2014"
//# This password is used for decrypting the key #
//akka.remote.netty.ssl.security.key-password="raysdata@2014"
//# This is the Java Key Store used by the client connection #
//akka.remote.netty.ssl.security.trust-store="tapp.keystore"
//# This password is used for decrypting the trust store #
//akka.remote.netty.ssl.security.trust-store-password="raysdata@2014"
//# Protocol to use for SSL encryption, choose from: #
//# Java 6 & 7: #
//#   'SSLv3', 'TLSv1' #
//# Java 7: #
//#   'TLSv1.1', 'TLSv1.2' #
//akka.remote.netty.ssl.security.protocol="TLSv1"
//# Example: ["TLS_RSA_WITH_AES_128_CBC_SHA", "TLS_RSA_WITH_AES_256_CBC_SHA"] #
//# You need to install the JCE Unlimited Strength Jurisdiction Policy Files to use AES 256. #
//# More info here: #
//# http://docs.oracle.com/javase/7/docs/technotes/guides/security/SunProviders.html#SunJCEProvider #
//akka.remote.netty.ssl.security.enabled-algorithms=["TLS_RSA_WITH_AES_128_CBC_SHA"]
//# There are three options, in increasing order of security: #
//# "" or SecureRandom  = > (default) #
//# "SHA1PRNG"  = > Can be slow because of blocking issues on Linux #
//# "AES128CounterSecureRNG"  = > fastest startup and based on AES encryption #
//# algorithm #
//# "AES256CounterSecureRNG" #
//# The following use one of 3 possible seed sources, depending on #
//# availability: /dev/random, random.org and SecureRandom (provided by Java) #
//# "AES128CounterInetRNG" #
//# "AES256CounterInetRNG" (Install JCE Unlimited Strength Jurisdiction #
//# Policy Files first) #
//# Setting a value here may require you to supply the appropriate cipher #
//# suite (see enabled-algorithms section above) #
//akka.remote.netty.ssl.security.random-number-generator=""
//# Dispatcher 默认派发器: default #
//akka.dispatcher.default.type=Dispatcher
//# 使用何种ExecutionService #
//akka.dispatcher.default.executor="fork-join-executor"
//# executor  =  "fork-join-executor" #
//# 配置 fork join 池 #
//# 容纳基于倍数的并行数量的线程数下限 #
//akka.dispatcher.default.fork-join-executor.parallelism-min=1
//#并行数（线程）: ceil(可用CPU数＊倍数） #
//akka.dispatcher.default.fork-join-executor.parallelism-factor=1.0
//#容纳基于倍数的并行数量的线程数上限 #
//akka.dispatcher.default.fork-join-executor.parallelism-max=10
//# Dispatcher  监控派发器：monitor #
//akka.dispatcher.monitor.type=Dispatcher
//# 使用何种ExecutionService #
//akka.dispatcher.monitor.executor="fork-join-executor"
//# executor  =  "fork-join-executor" #
//# 配置 fork join 池 #
//# 容纳基于倍数的并行数量的线程数下限 #
//akka.dispatcher.monitor.fork-join-executor.parallelism-min=1
//#并行数（线程）: ceil(可用CPU数＊倍数） #
//akka.dispatcher.monitor.fork-join-executor.parallelism-factor=1.0
//#容纳基于倍数的并行数量的线程数上限 #
//akka.dispatcher.monitor.fork-join-executor.parallelism-max=10
//# Dispatcher 处理派发器：processor #
//akka.dispatcher.processor.type=Dispatcher
//# 使用何种ExecutionService #
//akka.dispatcher.processor.executor="fork-join-executor"
//# executor  =  "fork-join-executor" #
//# 配置 fork join 池 #
//# 容纳基于倍数的并行数量的线程数下限 #
//akka.dispatcher.processor.fork-join-executor.parallelism-min=1
//#并行数（线程）: ceil(可用CPU数＊倍数） #
//akka.dispatcher.processor.fork-join-executor.parallelism-factor=1.0
//#容纳基于倍数的并行数量的线程数上限 #
//akka.dispatcher.processor.fork-join-executor.parallelism-max=10
//# Dispatcher  服务器派发器：server #
//akka.dispatcher.server.type=Dispatcher
//# 使用何种ExecutionService #
//akka.dispatcher.server.executor="fork-join-executor"
//# executor  =  "fork-join-executor" #
//# 配置 fork join 池 #
//# 容纳基于倍数的并行数量的线程数下限 #
//akka.dispatcher.server.fork-join-executor.parallelism-min=1
//# 并行数（线程）: ceil(可用CPU数＊倍数） #
//akka.dispatcher.server.fork-join-executor.parallelism-factor=1.0
//# 容纳基于倍数的并行数量的线程数上限 #
//akka.dispatcher.server.fork-join-executor.parallelism-max=10
//# Throughput 定义了线程切换到另一个actor之前处理的消息数上限 #
//# 设置成1表示尽可能公平. #
//akka.dispatcher.server.throughput=100
//# Dispatcher  性能指标派发器：metric #
//akka.dispatcher.metric.type=Dispatcher
//# 使用何种ExecutionService #
//akka.dispatcher.metric.executor="fork-join-executor"
//# executor  =  "fork-join-executor" #
//# 配置 fork join 池 #
//# 容纳基于倍数的并行数量的线程数下限 #
//akka.dispatcher.metric.fork-join-executor.parallelism-min=1
//# 并行数（线程） ... ceil(可用CPU数＊倍数） #
//akka.dispatcher.metric.fork-join-executor.parallelism-factor=1.0
//# 容纳基于倍数的并行数量的线程数上限 #
//akka.dispatcher.metric.fork-join-executor.parallelism-max=10
//# Throughput 定义了线程切换到另一个actor之前处理的消息数上限 #
//# 设置成1表示尽可能公平. #
//akka.dispatcher.metric.throughput=1
//# Dispatcher  词法分析派发器：executor #
//akka.dispatcher.executor.type=Dispatcher
//# 使用何种ExecutionService #
//akka.dispatcher.executor.executor="fork-join-executor"
//# executor  =  "fork-join-executor" #
//# 配置 fork join 池 #
//# 容纳基于倍数的并行数量的线程数下限 #
//akka.dispatcher.executor.fork-join-executor.parallelism-min=1
//# 并行数（线程）:ceil(可用CPU数＊倍数） #
//akka.dispatcher.executor.fork-join-executor.parallelism-factor=1.0
//# 容纳基于倍数的并行数量的线程数上限 #
//akka.dispatcher.executor.fork-join-executor.parallelism-max=10
//# Throughput 定义了线程切换到另一个actor之前处理的消息数上限 #
//# 设置成1表示尽可能公平. #
//akka.dispatcher.executor.throughput=1
//# include "akka-http-version" #
//# The value of the `Server` header to produce. #
//# Set to the empty string to disable rendering of the server header. #
//akka.http.server.server-header=raysdata-zeta-3.0/10.10.5#${akka.http.version} #spray-can/${spray.version}
//# Enables/disables SSL encryption. #
//# If enabled the server uses the implicit `ServerSSLEngineProvider` member #
//# of the `Bind` command to create `SSLEngine` instances for the underlying #
//# IO connection. #
//akka.http.server.ssl-encryption=off
//# The maximum number of requests that are accepted (and dispatched to #
//# the application) on one single connection before the first request #
//# has to be completed. #
//# Incoming requests that would cause the pipelining limit to be exceeded #
//# are not read from the connections socket so as to build up "back-pressure" #
//# to the client via TCP flow control. #
//# A setting of 1 disables HTTP pipelining, since only one request per #
//# connection can be "open" (i.e. being processed by the application) at any #
//# time. Set to higher values to enable HTTP pipelining. #
//# Set to 'disabled' for completely disabling pipelining limits #
//# (not recommended on public-facing servers due to risk of DoS attacks). #
//# This value must be > 0 and <= 128. #
//akka.http.server.pipelining-limit=64
//# The time after which an idle connection will be automatically closed. #
//# Set to `infinite` to completely disable idle connection timeouts. #
//akka.http.server.idle-timeout=30 s
//# If a request hasn't been responded to after the time period set here #
//# a `spray.http.Timedout` message will be sent to the timeout handler. #
//# Set to `infinite` to completely disable request timeouts. #
//akka.http.server.request-timeout=20 s
//# After a `Timedout` message has been sent to the timeout handler and the #
//# request still hasn't been completed after the time period set here #
//# the server will complete the request itself with an error response. #
//# Set to `infinite` to disable timeout timeouts. #
//akka.http.server.timeout-timeout=2 s
//# The period during which a service must respond to a `ChunkedRequestStart` message #
//# with a `RegisterChunkHandler` message. During the registration period reading from #
//# the network is suspended. It is still possible that some chunks have already been #
//# received which will be buffered until the registration is received or the timeout is #
//# triggered. If the timeout is triggered the connection is immediately aborted. #
//akka.http.server.chunkhandler-registration-timeout=500 ms
//# The path of the actor to send `spray.http.Timedout` messages to. #
//# If empty all `Timedout` messages will go to the "regular" request #
//# handling actor. #
//akka.http.server.timeout-handler=""
//# The "granularity" of timeout checking for both idle connections timeouts #
//# as well as request timeouts, should rarely be needed to modify. #
//# If set to `infinite` request and connection timeout checking is disabled. #
//akka.http.server.reaping-cycle=250 ms
//# Enables/disables support for statistics collection and querying. #
//# Even though stats keeping overhead is small, #
//# for maximum performance switch off when not needed. #
//akka.http.server.stats-support=on
//# Enables/disables the addition of a `Remote-Address` header #
//# holding the clients (remote) IP address. #
//akka.http.server.remote-address-header=off
//# Enables/disables the addition of a `Raw-Request-URI` header holding the #
//# original raw request URI as the client has sent it. #
//akka.http.server.raw-request-uri-header=off
//# Enables/disables automatic handling of HEAD requests. #
//# If this setting is enabled the server dispatches HEAD requests as GET #
//# requests to the application and automatically strips off all message #
//# bodies from outgoing responses. #
//# Note that, even when this setting is off the server will never send #
//# out message bodies on responses to HEAD requests. #
//akka.http.server.transparent-head-requests=on
//# Enables/disables an alternative response streaming mode that doesn't #
//# use `Transfer-Encoding: chunked` but rather renders the individual #
//# MessageChunks coming in from the application as parts of the original #
//# response entity. #
//# Enabling this mode causes all connections to be closed after a streaming #
//# response has been finished since there is no other way to signal the #
//# response end to the client. #
//# Note that chunkless-streaming is implicitly enabled when streaming #
//# responses to HTTP/1.0 clients (since they don't support #
//# `Transfer-Encoding: chunked`) #
//akka.http.server.chunkless-streaming=off
//# Enables/disables the returning of more detailed error messages to #
//# the client in the error response. #
//# Should be disabled for browser-facing APIs due to the risk of XSS attacks #
//# and (probably) enabled for internal or non-browser APIs. #
//# Note that spray will always produce log messages containing the full #
//# error details. #
//akka.http.server.verbose-error-messages=off
//akka.http.server.verbose-error-logging=on
//# If this setting is non-zero the HTTP server automatically aggregates #
//# incoming request chunks into full HttpRequests before dispatching them to #
//# the application. If the size of the aggregated requests surpasses the #
//# specified limit the server responds with a `413 Request Entity Too Large` #
//# error response before closing the connection. #
//# Set to zero to disable automatic request chunk aggregation and have #
//# ChunkedRequestStart, MessageChunk and ChunkedMessageEnd messages be #
//# dispatched to the handler. #
//akka.http.server.request-chunk-aggregation-limit=1m
//# The initial size if the buffer to render the response headers in. #
//# Can be used for fine-tuning response rendering performance but probably #
//# doesn't have to be fiddled with in most applications. #
//akka.http.server.response-header-size-hint=512
//# For HTTPS connections this setting specified the maximum number of #
//# bytes that are encrypted in one go. Large responses are broken down in #
//# chunks of this size so as to already begin sending before the response has #
//# been encrypted entirely. #
//akka.http.server.max-encryption-chunk-size=1m
//# The time period within which the TCP binding process must be completed. #
//# Set to `infinite` to disable. #
//akka.http.server.bind-timeout=1s
//# The time period within which the TCP unbinding process must be completed. #
//# Set to `infinite` to disable. #
//akka.http.server.unbind-timeout=1s
//# The time period within which a connection handler must have been #
//# registered after the bind handler has received a `Connected` event. #
//# Set to `infinite` to disable. #
//akka.http.server.registration-timeout=1s
//# The time after which a connection is aborted (RST) after a parsing error #
//# occurred. The timeout prevents a connection which is already known to be #
//# erroneous from receiving evermore data even if all of the data will be ignored. #
//# However, in case of a connection abortion the client usually doesn't properly #
//# receive the error response. This timeout is a trade-off which allows the client #
//# some time to finish its request and receive a proper error response before the #
//# connection is forcibly closed to free resources. #
//akka.http.server.parsing-error-abort-timeout=2s
//# If this setting is empty the server only accepts requests that carry a #
//# non-empty `Host` header. Otherwise it responds with `400 Bad Request`. #
//# Set to a non-empty value to be used in lieu of a missing or empty `Host` #
//# header to make the server accept such requests. #
//# Note that the server will never accept HTTP/1.1 request without a `Host` #
//# header, i.e. this setting only affects HTTP/1.1 requests with an empty #
//# `Host` header as well as HTTP/1.0 requests. #
//# Examples: `www.spray.io` or `example.com:8080` #
//akka.http.server.default-host-header=""
//# Enables/disables automatic back-pressure handling by write buffering and #
//# receive throttling #
//akka.http.server.automatic-back-pressure-handling=on
//# The reciprocal rate of requested Acks per NoAcks. E.g. the default value #
//# '10' means that every 10th write request is acknowledged. This affects the #
//# number of writes each connection has to buffer even in absence of back-pressure. #
//akka.http.server.back-pressure.noack-rate=10
//# The lower limit the write queue size has to shrink to before reads are resumed. #
//# Use 'infinite' to disable the low-watermark so that reading is resumed instantly #
//# after the next successful write. #
//akka.http.server.back-pressure.reading-low-watermark=infinite
//# Enables more verbose DEBUG logging for debugging SSL related issues. #
//akka.http.server.ssl-tracing=on
//# Modify to tweak parsing settings on the server-side only. #
//# parsing = ${spray.can.parsing} #
//akka.http.host-connector.max-connections=500
//akka.http.host-connector.max-retries=3
//akka.http.client.request-timeout=40s
//akka.http.client.connecting-timeout=2s
//akka.http.client.parsing.max-response-reason-length = 2014
//akka.http.client.ssl-tracing=on
//app-dispatcher.mailbox-requirement="com.raysdata.zeta.monitor.file.LocalFileMessageQueueSemantics"
//akka.actor.mailbox.requirements."com.raysdata.zeta.monitor.file.LocalFileMessageQueueSemantics"=app-dispatcher-mailbox
//app-dispatcher-mailbox.mailbox-type="com.raysdata.zeta.monitor.file.LocalFileMailbox"
//app.monitor-file.max.cache=1000000