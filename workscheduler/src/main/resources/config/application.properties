server.port=9101

mybatis.configuration.map-underscore-to-camel-case=true
spring.datasource.url=jdbc:mysql://192.168.1.100:3306/webtest?useUnicode=true&characterEncoding=utf-8&useSSL=false&rewriteBatchedStatements=true
spring.datasource.username=root
spring.datasource.password=123456
spring.datasource.driver-class-name=com.mysql.jdbc.Driver

mongodb.log.host = 192.168.1.104
mongodb.log.port = 27017
#mongodb.log.user = root
#mongodb.log.passwd = 123456
mongodb.log.db = test
mongodb.log.table = data
mongodb.log.buffertable = datatmp
mongodb.log.statustable = WF_STAT

logging.level.root=WARN
logging.level.org.springframework.web=INFO
logging.level.cn.com.carenet=DEBUG
logging.file=./logs/workflows_log.log
logging.pattern.console=[%d{yyyy-MM-dd HH:mm:ss} %p] %c{0}--%msg%n
logging.pattern.file=[%d{yyyy-MM-dd HH:mm:ss} %p] %c{0}--%msg%n

job.spark.submitcmd=spark-submit --jars /usr/hdp/2.5.0.0-1245/spark/lib/spark-assembly-1.6.2.2.5.0.0-1245-hadoop2.7.3.2.5.0.0-1245.jar --jars /usr/hdp/2.5.0.0-1245/spark/lib/spark-examples-1.6.2.2.5.0.0-1245-hadoop2.7.3.2.5.0.0-1245.jar --master yarn-client --driver-memory 600m --num-executors 4  --executor-cores 4 --executor-memory 4G  --class cn.com.carenet.spark.run.RunnerTools
job.spark.frameworkurl=/opt/workflows/framework/spark.jar
job.spark.workflowsurl=/opt/workflows/data/sparkjob

job.storm.frameworkurl=/opt/workflows/framework
job.storm.nimbusseeds=["192.168.1.104"]
job.storm.nimbusthriftport=6627

#map reduce jar
job.hadoop.jarurl=/opt/workflows/framework/newBeeMapReduce.jar

job.execute.retrytimes=5

#hdfs.keytab.file=
#hdfs.kerberos.principal=
#storm.keytab.file=
#storm.kerberos.principal=
#hive.keytab.file=
#hive.kerberos.principal=
